{"id":2143,"date":"2020-08-10T09:31:18","date_gmt":"2020-08-10T09:31:18","guid":{"rendered":"http:\/\/dadd-project.org\/?p=2143"},"modified":"2020-08-10T10:15:53","modified_gmt":"2020-08-10T10:15:53","slug":"discovering-and-categorising-language-biases-in-reddit","status":"publish","type":"post","link":"https:\/\/dadd-project.org\/2020\/08\/10\/discovering-and-categorising-language-biases-in-reddit\/","title":{"rendered":"Discovering and Categorising Language Biases in Reddit"},"content":{"rendered":"\n<p>Our article &#8220;<a href=\"https:\/\/www.researchgate.net\/publication\/343498904_Discovering_and_Categorising_Language_Biases_in_Reddit\">Discovering and Categorising Language Biases in Reddit<\/a>&#8221; was accepted last week at the International Conference on Web and Social Media 2021 (ICWSM 2021). Although the proceedings will not be ready until early 2021, you can find the author&#8217;s version of the paper <a href=\"https:\/\/www.researchgate.net\/publication\/343498904_Discovering_and_Categorising_Language_Biases_in_Reddit\">here<\/a>. <\/p>\n\n\n\n<p>We present a method to explore language bias in various Reddit communities by comparing the words most closely correlated with different concepts leveraging the embedding space of each community. In this way, we study gender bias in r\/TheRedPill, religion bias in r\/Atheism, and ethnicity bias in r\/The_Donald, and discover important biases that, for instance in r\/TheRedPill, picture women with words related to externality and physical appearance such as <em>flirtatious<\/em> and <em>fuckable<\/em>, and men through descriptive adjectives serving as indicators of subjectivity such as <em>visionary<\/em> and <em>tactician<\/em> (see our <a href=\"https:\/\/xfold.github.io\/WE-GenderBiasVisualisationWeb\/\">Bias Visualisation Tool<\/a>).<\/p>\n\n\n\n<p>Also, in case you are interested in analysing language biases in your own datasets, we are also sharing the code <a href=\"https:\/\/github.com\/xfold\/LanguageBiasesInReddit\">here<\/a>. Please use it and feel free to ask any questions or report any errors\/problems you find on Github!<\/p>\n\n\n\n<p><strong>Abstract.<\/strong> <em>We present a data-driven approach using word embeddings to discover and categorise language biases on the discussion platform Reddit. As spaces for isolated user communities, platforms such as Reddit are increasingly connected to issues of racism, sexism and other forms of discrimination. Hence, there is a need to monitor the language of these groups. One of the most promising AI approaches to trace linguistic biases in large textual datasets involves word embeddings, which transform text into high-dimensional dense vectors and capture semantic relations between words. Yet, previous studies require predefined sets of potential biases to study, e.g., whether gender is more or less associated with particular types of jobs. This makes these approaches unfit to deal with smaller and community-centric datasets such as those on Reddit, which contain smaller vocabularies and slang, as well as biases that may be particular to that community. This paper proposes a data-driven approach to automatically discover language biases encoded in the vocabulary of online discourse communities on Reddit. In our approach, protected attributes are connected to evaluative words found in the data, which are then categorised through a semantic analysis system. We verify the effectiveness of our method by comparing the biases we discover in the Google News dataset with those found in previous literature. We then successfully discover gender bias, religion bias, and ethnic bias in different Reddit communities. We conclude by discussing potential application scenarios and limitations of this data-driven bias discovery method.<\/em><\/p>\n\n\n\n<p><\/p>\n","protected":false},"excerpt":{"rendered":"<p>Our article &#8220;Discovering and Categorising Language Biases in Reddit&#8221; was accepted last week at the International Conference on Web and Social Media 2021 (ICWSM 2021). Although the proceedings will not be ready until early 2021, you can find the author&#8217;s version of the paper here. We present a method to explore language bias in various &hellip; <\/p>\n<p class=\"link-more\"><a href=\"https:\/\/dadd-project.org\/2020\/08\/10\/discovering-and-categorising-language-biases-in-reddit\/\" class=\"more-link\">Continue reading<span class=\"screen-reader-text\"> &#8220;Discovering and Categorising Language Biases in Reddit&#8221;<\/span><\/a><\/p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"closed","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[1],"tags":[6,3,7,8,5],"_links":{"self":[{"href":"https:\/\/dadd-project.org\/wp-json\/wp\/v2\/posts\/2143"}],"collection":[{"href":"https:\/\/dadd-project.org\/wp-json\/wp\/v2\/posts"}],"about":[{"href":"https:\/\/dadd-project.org\/wp-json\/wp\/v2\/types\/post"}],"author":[{"embeddable":true,"href":"https:\/\/dadd-project.org\/wp-json\/wp\/v2\/users\/1"}],"replies":[{"embeddable":true,"href":"https:\/\/dadd-project.org\/wp-json\/wp\/v2\/comments?post=2143"}],"version-history":[{"count":4,"href":"https:\/\/dadd-project.org\/wp-json\/wp\/v2\/posts\/2143\/revisions"}],"predecessor-version":[{"id":2148,"href":"https:\/\/dadd-project.org\/wp-json\/wp\/v2\/posts\/2143\/revisions\/2148"}],"wp:attachment":[{"href":"https:\/\/dadd-project.org\/wp-json\/wp\/v2\/media?parent=2143"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https:\/\/dadd-project.org\/wp-json\/wp\/v2\/categories?post=2143"},{"taxonomy":"post_tag","embeddable":true,"href":"https:\/\/dadd-project.org\/wp-json\/wp\/v2\/tags?post=2143"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}